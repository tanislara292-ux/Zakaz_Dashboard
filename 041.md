Задача: боевой прогон QTickets API после фикса формата offset

Цель: убедиться, что обновлённый клиент корректно формирует фильтры (+03 (line 0)), QTickets возвращает свежие заказы, а наш пайплайн (loader + ClickHouse) обрабатывает их без ошибок.

Исходные условия: работаем в dev‑окружении с доступом к боевому API QTickets (учётка irs-prod, рабочий токен). DRY_RUN выключаем, так что все операции пойдут в настоящий ClickHouse.

1. Подготовка окружения

1.1. Убедиться, что main подтянут: git fetch --all && git checkout main && git pull --ff-only.

1.2. Пересобрать образ qtickets_api:latest (из корня dashboard-mvp):
docker build -f integrations/qtickets_api/Dockerfile -t qtickets_api:latest .

1.3. Обновить prod dotenv (например, /opt/zakaz_dashboard/secrets/.env.qtickets_api):
DRY_RUN=false, действующие QTICKETS_TOKEN и ORG_NAME=irs-prod, остальные CLICKHOUSE_* совпадают со схемой из bootstrap_clickhouse.sh.

1.4. Перезапустить ClickHouse при необходимости (scripts/bootstrap_clickhouse.sh) и убедиться, что сервис healthy.

2. Фиксация начального состояния

2.1. Снять состояние таблиц:

SELECT count() FROM zakaz.stg_qtickets_api_orders_raw;
SELECT count() FROM zakaz.fact_qtickets_sales_daily;
SELECT job, status, finished_at FROM zakaz.meta_job_runs WHERE job='qtickets_api' ORDER BY finished_at DESC LIMIT 3;
2.2. Сохранить выводы в лог-файл (logs/qtickets_prod_run_before.txt).

3. Сценарии боевых вызовов API (curl)

Все запросы выполняем с реальным токеном; межу вызовами фиксируем timestamp, HTTP код, тело и запись в Markdown (logs/qtickets_api_live.md).

3.1. GET /orders — окно последних 48 часов:
where с payed=1, payed_at >= (now-48h) и < now; orderBy={"payed_at":"desc"}; per_page=200.

Проверить, что URL содержит +03 (line 0).
При HTTP 200: убедиться, что payed_at соответствует диапазону.
При 4xx/5xx: сохранить body, заголовки, повторить после паузы (не более 3 попыток).
3.2. Pagination — если meta.has_next=true, запросить page=2, чтобы удостовериться, что фильтр сохраняется и код формирует page.

3.3. GET /orders/{id} — взять id из любого свежего заказа и запросить детали. Проверить, что payed_at совпадает.

3.4. Fallback POST — то же окно, но через метод POST (JSON‑body). Проверить, что тело совпадает с GET, формат +03 (line 0). Записать HTTP код (ожидаем 200; при 503 зафиксировать).

3.5. GET /events — убедиться, что работа сопутствующих запросов не затронута (должен вернуться список без ошибок).

4. Запуск Python loader’а

4.1. Выполнить контейнер в prod-режиме:

docker run --rm \
  --network clickhouse_default \
  --env-file /opt/zakaz_dashboard/secrets/.env.qtickets_api \
  qtickets_api:latest
4.2. Захватить stdout/ stderr в logs/qtickets_loader_prod.log.

4.3. Проверить, что лог содержит:

строки “Fetching orders via GET…”;
where/orderBy с +03 (line 0);
отсутствие Traceback;
итог “Inserted X rows into zakaz.fact_qtickets_sales_daily” или “0 rows” (если продаж нет).
4.4. Если API вернул 503 → убедиться, что клиент перешёл на POST fallback или завершил попытки по retry. Зафиксировать финальный статус (ok/error) в meta_job_runs.

5. Верификация ClickHouse после запуска

5.1. Выполнить:

SELECT count(), max(_loaded_at) FROM zakaz.stg_qtickets_api_orders_raw;
SELECT min(sales_date), max(sales_date), sum(revenue) FROM zakaz.fact_qtickets_sales_daily;
SELECT * FROM zakaz.meta_job_runs WHERE job='qtickets_api' ORDER BY finished_at DESC LIMIT 1;
5.2. Сверить, что количество строк увеличилось (если API вернул данные). Если записей нет — фиксируем, что API пустой, но запуск завершился status='ok'.

6. Приложить артефакты

Markdown-отчёт logs/qtickets_api_live.md с таблицей запросов (timestamp, method, URL, HTTP код, заметки).
Лог qtickets_loader_prod.log.
Snapshot таблиц до/после (qtickets_ch_state_before.txt, qtickets_ch_state_after.txt).
Если были ошибки (503/500) — отдельный файл qtickets_api_errors.json с ответами сервера.
Definition of Done

Все описанные curl-сценарии выполнены; для каждого есть HTTP код и (при успехе) выдержка из ответа.
Loader отработал, лог сохранён; никаких необработанных исключений.
ClickHouse содержит актульную запись в meta_job_runs за текущий запуск; результаты запросов count() задокументированы.
В отчёте ясно указано, возвращает ли API свежие продажи или только исторический архив.
При любых сбоях приложены логи и аргументы, что это проблема QTickets, а не клиента.