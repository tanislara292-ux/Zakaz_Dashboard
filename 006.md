Task 006 — Full Schema & Integration Lockdown

Goal: deliver a repository where every ClickHouse schema entry point produces the exact same objects, bootstrap/smoke tests pass end-to-end, and all proofs are captured. No shortcuts, no “assumed” steps.

0. Prep
Start from a clean branch off current origin/main.
Record git status before/after each major phase; don’t discard evidence.
1. Canonical Schema Sweep
cd dashboard-mvp/infra/clickhouse
Run rg "CREATE TABLE IF NOT EXISTS zakaz.dim_events" -g "*.sql"
→ list of files. For each file in order below:
bootstrap_schema.sql
bootstrap_all.sql
init.sql
init_qtickets_sheets.sql
init_integrations.sql
migrations/2025-qtickets-api.sql
migrations/2025-qtickets-api-final.sql
any other hit from the rg command
Inside each file:
Keep exactly one dim_events definition using the canonical columns:
event_id String, event_name String, city LowCardinality(String), start_date Nullable(Date), end_date Nullable(Date), tickets_total UInt32 DEFAULT 0, tickets_left UInt32 DEFAULT 0, _ver UInt64, _loaded_at DateTime DEFAULT now().
Delete or rewrite any conflicting definition (e.g., legacy event_date layout).
Immediately before each CREATE, add DROP TABLE IF EXISTS zakaz.dim_events; unless the file is meant to be fully idempotent (note: bootstrap dump should stay drop-free; migrations/init scripts must drop-and-create so later files can’t resurrect old schemas).
Repeat steps 2–3 for:
fact_qtickets_inventory
fact_qtickets_inventory_latest
stg_vk_ads_daily
any other table touched by the recent schema changes
Use canonical definitions already present in bootstrap_schema.sql as the single source of truth. No other structure is acceptable.
2. View & MV Alignment
For every view/materialized view referencing those tables (search with rg "dim_events" -n dashboard-mvp/infra/clickhouse and similar for other tables):

Inspect SELECT statements and argMax/column references.
Ensure they only use columns available in the canonical definitions.
Remove any join/filter on legacy columns (e.g., event_date).
Confirm TTL/PARTITION/ORDER BY clauses stay deterministic. Replace expressions using today()/now() inside PARTITION BY with fixed column-based equivalents.
3. Validator Improvements
Open scripts/validate_clickhouse_schema.py.
Extend DDL_FILES list to include:
init_qtickets_sheets.sql
init_integrations.sql
migrations/2025-qtickets-api.sql
migrations/2025-qtickets-api-final.sql
any other SQL file the bootstrap path might execute.
Add a check that reports if the same table name appears with differing column sets across files. Approach:
Build a map table -> list[set(columns)].
If len(set_of_frozensets) > 1, print a blocking error detailing file names.
Keep existing partition/view checks intact.
4. Bootstrap Execution (Real Runs)
Perform on a machine with Docker access (not the read-only environment):

rm -rf infra/clickhouse/data infra/clickhouse/logs (ensure you’re not wiping prod data).
cp infra/clickhouse/.env.example infra/clickhouse/.env
Run dashboard-mvp/scripts/bootstrap_clickhouse.sh.
Save full terminal output.
Expected: health check success, SHOW TABLES lists canonical tables.
Re-run the same script without removing volumes.
Confirm no errors, especially no schema conflicts.
After second run, capture the result of
docker exec ch-zakaz clickhouse-client -q "DESCRIBE TABLE zakaz.dim_events FORMAT TabSeparatedWithNames" (same for fact_qtickets_inventory and fact_qtickets_inventory_latest). Attach outputs to the audit report.
5. Smoke & Tests
dashboard-mvp/scripts/smoke_qtickets_dryrun.sh --env-file <path>
Use the real .env.qtickets_api sample (update tokens as necessary).
Confirm exit code is 0.
Snapshot meta_job_runs before and after (the script prints this; copy the logs into the report).
cd dashboard-mvp/vk-python && python -m pytest.
From repo root: python scripts/validate_clickhouse_schema.py.
python -m compileall dashboard-mvp.
Optionally run docker build -f dashboard-mvp/integrations/qtickets_api/Dockerfile -t qtickets_api:test .
Rerun GitHub Actions workflow locally (if you use act) or push to a test branch to confirm CI stages pass; collect job URLs/results.
6. Documentation and Evidence
Update ZAKAZ_DASHBOARD_AUDIT_REPORT.md:
new timestamp
explicit command outputs for each step above.
Update or create new ADR: docs/adr/ADR-006-clickhouse-schema-unification.md. Summarize:
why previous attempts failed
chosen canonical schema
policy for future migrations (add new migration or modify bootstrap, but both must stay consistent).
Update docs/changelog/CHANGELOG-006.md with before/after details, especially pointing out the deleted duplicates and new validator behavior.
If README/CONTRIBUTING mentions manual fixes, revise to say “no manual edits required” and point to the scripts.
Check .github/workflows/ci.yml; if additional SQL files are now validated or extra jobs added, reflect this in comments or docs.
7. Final Verification Checklist (must all be “YES”)
rg search confirms only one definition per table in each SQL file, with identical column order/types.
Validator reports “Schema validation passed.”
Two consecutive bootstrap_clickhouse.sh runs succeed (logs attached).
Smoke script exit code 0; meta_job_runs unaffected.
python -m pytest green.
python -m compileall dashboard-mvp green.
Docker build for Qtickets succeeds.
ADR + changelog + audit updated.
git status only shows intended changes.
Send a final note summarizing each checklist item with “OK”/“FAIL” plus links or inline snippets to the captured outputs. No acceptance until every box is confirmed with evidence.