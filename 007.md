Task 007 — ClickHouse Schema Canonicalization & Test Evidence
Цель
Обеспечить, чтобы каждый SQL-источник в dashboard-mvp/infra/clickhouse/ создавал идентичную схему ClickHouse, валидатор ловил любые расхождения, а полный цикл bootstrap → smoke → тесты → документация был выполнен и задокументирован.

0. Среда
Рабочая ветка от origin/main, чистый git status.
Машина с Docker (включая docker compose) и Python 3.11+.
Все команды выполнять из корня репозитория Zakaz_Dashboard, если не указано иное.
Для каждого блока фиксировать ключевые выводы (логи/скриншоты/файлы) для отчета.
1. Инвентаризация и выбор эталона
1.1. Соберите список всех SQL с определениями CREATE TABLE IF NOT EXISTS:

rg "CREATE TABLE IF NOT EXISTS zakaz\." -n -g "*.sql" dashboard-mvp/infra/clickhouse
Сохраните вывод, он должен включать как минимум:

bootstrap_schema.sql
bootstrap_all.sql
init.sql
init_qtickets_sheets.sql
init_integrations.sql
migrations/2025-qtickets-api.sql
migrations/2025-qtickets-api-final.sql
возможные дополнительные файлы (если найдены — добавить в план).
1.2. Эталоном схем считаем актуальные определения в dashboard-mvp/infra/clickhouse/bootstrap_schema.sql. Для сверки выпишите полный текст CREATE TABLE для следующих объектов (в этом файле):

zakaz.dim_events
zakaz.fact_qtickets_inventory
zakaz.fact_qtickets_inventory_latest
zakaz.stg_vk_ads_daily
zakaz.stg_qtickets_api_orders_raw
zakaz.stg_qtickets_api_inventory_raw
zakaz.fact_qtickets_sales_daily
(при необходимости добавить другие ключевые таблицы).
2. Приведение SQL-файлов к единой схеме
Для каждого обнаруженного файла из шага 1 (по порядку):

2.1. Найдите определение интересующей таблицы.
2.2. Перепишите его так, чтобы буквально совпадало с эталонным вариантом: порядок колонок, типы, дефолты, комментарии, настройки ENGINE/PARTITION/ORDER BY/SETTINGS.
2.3. Если файл используется как миграция/инициализация (а не итоговый bootstrap dump) и должен пересоздавать таблицу, добавьте прямо перед CREATE TABLE строку:

DROP TABLE IF EXISTS zakaz.<table_name>;
(Не добавляйте DROP в bootstrap_schema.sql и bootstrap_all.sql, где требуется чистая идемпотентность.)

2.4. Убедитесь, что таблица zakaz.fact_qtickets_inventory присутствует во всех релевантных файлах (раньше отсутствовала в migrations/2025-qtickets-api.sql).

2.5. Повторите действия для каждой таблицы из списка 1.2 во всех файлах. Если встречаются новые таблицы с конфликтующими схемами — привести к канону или обсудить, но документировать в отчете.

2.6. Просмотрите зависимые VIEW/MV в каждом файле:

dim_events → проверьте ссылки на start_date/end_date/_loaded_at.
fact_qtickets_inventory_latest → все запросы должны ожидать LowCardinality(String) и Nullable поля, если так в эталоне.
Удалите или адаптируйте устаревшие SELECT’ы с event_date, city String и т.д.
2.7. По завершении выполните git diff и сохраните выдержки, показывающие унификацию определений.

3. Расширение валидатора
3.1. Откройте scripts/validate_clickhouse_schema.py.

3.2. Обновите список DDL_FILES, добавив все SQL, найденные на шаге 1 (минимум init_qtickets_sheets.sql, init_integrations.sql, обе миграции). Если обнаружены дополнительные файлы — добавить их туда же.

3.3. Реализуйте проверку, которая гарантирует одинаковость схем:

При чтении SQL формируйте структуру table -> {frozenset(columns_with_types)}.
Если у таблицы более одного уникального набора колонок (включая типы и порядок), выводите критическую ошибку с указанием всех файлов, где найдены отличия. Скрипт должен завершаться кодом 1.
3.4. Сохраните функциональность проверки представлений и PARTITION BY.

3.5. Запустите скрипт и убедитесь, что он падает при искусственно внесенном рассогласовании (для проверки), затем верните правильную версию. Приложите вывод к отчету.

4. Двойной bootstrap (реальная машина)
4.1. Очистите данные ClickHouse (осторожно, не в проде!):

rm -rf dashboard-mvp/infra/clickhouse/data dashboard-mvp/infra/clickhouse/logs
4.2. Подготовьте .env:

cd dashboard-mvp/infra/clickhouse
cp .env.example .env
4.3. Запустите первый bootstrap:

../scripts/bootstrap_clickhouse.sh | tee ../../logs/bootstrap_first.log
Лог сохранить (путь logs/bootstrap_first.log или аналог).
4.4. Не очищая data/logs, сразу запустите второй раз:

../scripts/bootstrap_clickhouse.sh | tee ../../logs/bootstrap_second.log
4.5. После второго запуска зафиксируйте описания ключевых таблиц (вывод сохранить в файлы):

docker exec ch-zakaz clickhouse-client -q "DESCRIBE TABLE zakaz.dim_events FORMAT TabSeparatedWithNames" \
  | tee ../../logs/describe_dim_events.tsv

docker exec ch-zakaz clickhouse-client -q "DESCRIBE TABLE zakaz.fact_qtickets_inventory FORMAT TabSeparatedWithNames" \
  | tee ../../logs/describe_fact_inv.tsv

docker exec ch-zakaz clickhouse-client -q "DESCRIBE TABLE zakaz.fact_qtickets_inventory_latest FORMAT TabSeparatedWithNames" \
  | tee ../../logs/describe_fact_inv_latest.tsv
4.6. Проверить, что оба bootstrap завершились без ошибок; если нет — зафиксировать проблему, устранить, повторить шаги.

5. Smoke и тесты
5.1. Выполните DRY_RUN smoke (используйте актуальный .env):

dashboard-mvp/scripts/smoke_qtickets_dryrun.sh --env-file <путь_к_env> | tee logs/smoke_qtickets.log
Проверить в логе: exit code 0, meta_job_runs до/после не изменился.
5.2. Python-тесты и компиляция:

python scripts/validate_clickhouse_schema.py | tee logs/schema_validation.log
python -m compileall dashboard-mvp | tee logs/compileall.log
cd dashboard-mvp/vk-python && python -m pytest | tee ../../logs/pytest.log
5.3. Сборка Docker:

docker build -f dashboard-mvp/integrations/qtickets_api/Dockerfile -t qtickets_api:test . \
  | tee logs/docker_build.log
5.4. Если используется CI (GitHub Actions):

При необходимости запустить act или пушнуть ветку, дождаться результатов.
Сохранить ссылку/лог pipeline.
6. Документация и артефакты
6.1. Обновите/создайте:

docs/adr/ADR-007-clickhouse-schema-lockdown.md — описать проблему, решение, правила на будущее (включая требование синхронных изменений во всех SQL и включение их в валидатор).
docs/changelog/CHANGELOG-007.md — что изменено, какие тесты выполнены, ссылки на логи.
ZAKAZ_DASHBOARD_AUDIT_REPORT.md — добавить свежий блок со всеми командами, результатами, расположением логов (logs/bootstrap_first.log, etc.).
README/CONTRIBUTING при необходимости обновить инструкции или ссылки.
6.2. Все журналы/файлы логов сложить в каталог logs/ (или выбрать иное единое место) и упомянуть в отчете.

6.3. Сделать git status, убедиться, что нет неожиданных файлов; если есть временные логи, добавить в .gitignore или переместить в артефакты CI.

6.4. Создать коммит(ы) с осмысленным сообщением (например, task-007: unify clickhouse schema).

Приемка (Definition of Done)
Task считается выполненной, если:

Схема: во всех SQL-файлах, найденных на шаге 1, таблицы dim_events, fact_qtickets_inventory, fact_qtickets_inventory_latest, stg_vk_ads_daily, stg_qtickets_api_orders_raw, stg_qtickets_api_inventory_raw, fact_qtickets_sales_daily имеют идентичные определения; нет старых вариантов с event_date/city String/без _loaded_at.

Валидатор:

Скрипт покрывает все SQL-файлы.
При расхождении схемы запускается ошибка (проверено вручную).
Текущий запуск завершился сообщением Schema validation passed.
Bootstrap:

Первый и второй запуск прошли без ошибок.
Логи и DESCRIBE таблиц сохранены и приложены.
Smoke/Test:

smoke_qtickets_dryrun.sh завершился с exit code 0, meta_job_runs не изменился.
python -m pytest, python -m compileall, python scripts/validate_clickhouse_schema.py, docker build — все завершились успешно, логи сохранены.
Документация:

ADR-007, CHANGELOG-007, ZAKAZ_DASHBOARD_AUDIT_REPORT.md обновлены и описывают выполненные шаги с указанием логов.
Инструкции по Bootstrap/Smoke отражают актуальные файлы и команды.
Git:

Репозиторий чист, закоммичены только изменения по задаче.
Коммит(ы) содержат ясное описание.
Отчет:

В финальном сообщении приложен чек-лист с отметками OK/FAIL для каждого вышеуказанного пункта и ссылками на соответствующие логи/файлы.
Без выполнения любого из пунктов задача не принимается.